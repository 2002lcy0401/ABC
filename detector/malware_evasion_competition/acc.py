import torch
import torch.nn.functional as F
from MalConv import MalConv
from ember import predict_sample
import lightgbm as lgb
import numpy as np
import os
import sys

MALCONV_MODEL_PATH = 'models/malconv/malconv.checkpoint'
NONNEG_MODEL_PATH = 'models/nonneg/nonneg.checkpoint'
EMBER_MODEL_PATH = 'models/ember/ember_model.txt'

class MalConvModel(object):
    def __init__(self, model_path, thresh=0.5, name='malconv'):
        self.model = MalConv(channels=256, window_size=512, embd_size=8).train()
        weights = torch.load(model_path, map_location='cpu')
        self.model.load_state_dict(weights['model_state_dict'])
        self.thresh = thresh
        self.__name__ = name

    def predict(self, bytez):
        _inp = torch.from_numpy(np.frombuffer(bytez, dtype=np.uint8)[np.newaxis, :])
        with torch.no_grad():
            outputs = F.softmax(self.model(_inp), dim=-1)
        return outputs.detach().numpy()[0, 1] > self.thresh

class EmberModel(object):
    def __init__(self, model_path=EMBER_MODEL_PATH, thresh=0.8336, name='ember'):
        self.model = lgb.Booster(model_file=model_path)
        self.thresh = thresh
        self.__name__ = 'ember'

    def predict(self, bytez):
        return predict_sample(self.model, bytez) > self.thresh

def classify_files_in_folder(folder_path, label, models):
    files = os.listdir(folder_path)
    results = {model.__name__: {'correct': 0, 'total': len(files)} for model in models}
    
    for file_name in files:
        file_path = os.path.join(folder_path, file_name)
        with open(file_path, 'rb') as infile:
            bytez = infile.read()
        
        for model in models:
            prediction = model.predict(bytez)
            predicted_label = "malicious" if prediction else "benign"
            
            if predicted_label == label:
                results[model.__name__]['correct'] += 1

    return results

def main():
    if len(sys.argv) != 3:
        print("Usage: python batch_test.py <benign_folder> <malicious_folder>")
        sys.exit(1)

    benign_folder = sys.argv[1]
    malicious_folder = sys.argv[2]

    # Initialize models
    malconv = MalConvModel(MALCONV_MODEL_PATH, thresh=0.5)
    nonneg_malconv = MalConvModel(NONNEG_MODEL_PATH, thresh=0.35, name='nonneg_malconv')
    ember = EmberModel(EMBER_MODEL_PATH, thresh=0.8336)
    models = [malconv, nonneg_malconv, ember]

    benign_results = classify_files_in_folder(benign_folder, "benign", models)
    malicious_results = classify_files_in_folder(malicious_folder, "malicious", models)

    for model in models:
        model_name = model.__name__
        correct_predictions = benign_results[model_name]['correct'] + malicious_results[model_name]['correct']
        total_files = benign_results[model_name]['total'] + malicious_results[model_name]['total']
        accuracy = correct_predictions / total_files

        print(f"{model_name} - Benign files: {benign_results[model_name]['correct']}/{benign_results[model_name]['total']} correct")
        print(f"{model_name} - Malicious files: {malicious_results[model_name]['correct']}/{malicious_results[model_name]['total']} correct")
        print(f"{model_name} - Overall accuracy: {accuracy:.2%}")

if __name__ == "__main__":
    main()
